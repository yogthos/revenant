{
  "llm": {
    "_comment": "Provider selection: critic for repair, rtt for neutralization (deepseek or mlx)",
    "provider": {
      "critic": "deepseek",
      "rtt": "deepseek"
    },
    "providers": {
      "deepseek": {
        "api_key": "${DEEPSEEK_API_KEY}",
        "base_url": "https://api.deepseek.com",
        "model": "deepseek-chat",
        "max_tokens": 4096,
        "temperature": 0.7,
        "timeout": 120
      },
      "ollama": {
        "base_url": "http://localhost:11434",
        "model": "llama3",
        "max_tokens": 4096,
        "temperature": 0.7
      },
      "mlx_rtt": {
        "model": "mlx-community/Qwen2.5-3B-Instruct-4bit",
        "max_tokens": 512,
        "temperature": 0.1,
        "top_p": 0.9
      },
      "deepseek_rtt": {
        "model": "deepseek-chat",
        "max_tokens": 8192,
        "temperature": 0.1,
        "batch_size": 10,
        "concurrent_batches": 8,
        "timeout": 180
      }
    },
    "retry": {
      "max_attempts": 5,
      "base_delay": 2,
      "max_delay": 60
    }
  },
  "generation": {
    "_comment": "Repair and length settings",
    "max_repair_attempts": 5,
    "_comment3": "Length control (target_expansion_ratio: 1.5 = 50% longer output for author flourish)",
    "max_expansion_ratio": 3.0,
    "target_expansion_ratio": 2.0,
    "_comment3a": "expand_for_texture: add stronger prompt to encourage elaboration/flourishes",
    "expand_for_texture": false,
    "_comment4": "LoRA adapters with per-adapter generation settings (enabled: true/false to toggle)",
    "lora_adapters": {
      "lora_adapters/lovecraft_32b": {
        "_comment": "Qwen2.5-32B trained on RunPod A100, checkpoint-600 has best val_loss",
        "enabled": true,
        "scale": 2.0,
        "temperature": 0.7,
        "top_p": 0.95,
        "min_p": 0.03,
        "repetition_penalty": 1.05,
        "max_tokens": 1024,
        "worldview": "lovecraft_worldview.txt",
        "checkpoint": "checkpoint-600"
      },
      "lora_adapters/lovecraft_14b": {
        "_comment": "Qwen2.5-14B local MLX training",
        "enabled": false,
        "scale": 2.0,
        "temperature": 0.8,
        "top_p": 0.96,
        "min_p": 0.03,
        "repetition_penalty": 1.08,
        "max_tokens": 1024,
        "worldview": "lovecraft_worldview.txt"
      }
    },
    "_comment5": "Neutralization (skip for better fact preservation)",
    "skip_neutralization": false,
    "_comment6": "Post-processing",
    "repetition_threshold": 3,
    "reduce_repetition": true,
    "_comment6a": "Sentence restructuring (convert balanced patterns to organic)",
    "restructure_sentences": false,
    "_comment6b": "Sentence splitting (break run-on sentences at conjunction points)",
    "split_sentences": true,
    "max_sentence_length": 60,
    "sentence_length_variance": 0.3,
    "_comment6c": "Grammar correction (style-safe, preserves author voice)",
    "correct_grammar": true,
    "grammar_language": "en-US",
    "_comment7": "Document handling",
    "use_document_context": true,
    "pass_headings_unchanged": true,
    "min_paragraph_words": 10,
    "_comment8": "RAG settings",
    "use_structural_rag": true,
    "use_structural_grafting": true,
    "rag_sample_size": 200,
    "_comment9": "Persona settings (subjective voice to defeat AI detection)",
    "use_persona": true,
    "_comment10": "Input perturbation (8% noise to match training distribution)",
    "apply_input_perturbation": true
  },
  "style": {
    "_comment": "Perspective controls output point-of-view",
    "_options": "preserve | first_person_singular | first_person_plural | third_person | author_voice_third_person",
    "perspective": "preserve"
  },
  "validation": {
    "_comment": "Semantic validation settings",
    "entailment_threshold": 0.7,
    "max_hallucinations_before_reject": 3
  },
  "log_level": "INFO"
}
